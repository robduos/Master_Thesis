{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "185d8123-0676-4e00-b1a5-159b7dbc73c7",
   "metadata": {},
   "source": [
    "Script Description:\n",
    "This script reads and extracts GPP_NT & RECO_NT from all the individual NOBV CSV Files, computes the daily averages of the features, reads the pre-processed complete dataset, merges the two columns to the complete dataset and exports the merged dataset.\n",
    "\n",
    "File Name: 01_02_Filter_Merge_EC_Tower_Data_GPP.ipynb\n",
    "\n",
    "Date: 2025\n",
    "\n",
    "Created by: Rob Alamgir\n",
    "\n",
    "Version: 1.0\n",
    "\n",
    "References:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38438590-bb47-4a6c-afd8-0931cb5fe1d7",
   "metadata": {},
   "source": [
    "#### Import the relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8191364a-e3dd-4ba8-bf49-903ffc7f139e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f880ce2f-76e6-44df-8f81-becab6039cfe",
   "metadata": {},
   "source": [
    "#### Extract and Merge data from all the indivdual CSV files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "083a63f6-69ad-4fde-82be-ee66260ddfef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully extracted!\n",
      "\n",
      "Files with data:\n",
      "['ALB_MS_GPP_RECO.csv', 'ALB_RF_GPP_RECO.csv', 'AMM_GPP_RECO.csv', 'AMR_GPP_RECO.csv', 'BUO_GPP_RECO.csv', 'BUW_GPP_RECO.csv', 'HOC_GPP_RECO.csv', 'HOH_GPP_RECO.csv', 'LDC_GPP_RECO.csv', 'LDH_GPP_RECO.csv']\n",
      "\n",
      "Files without data:\n",
      "[]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 425510 entries, 0 to 425509\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   Unnamed: 0  425510 non-null  int64  \n",
      " 1   datetime    425510 non-null  object \n",
      " 2   day         425510 non-null  object \n",
      " 3   hour        425510 non-null  float64\n",
      " 4   location    425510 non-null  object \n",
      " 5   GPP_NT      372236 non-null  float64\n",
      " 6   RECO_NT     424916 non-null  float64\n",
      "dtypes: float64(3), int64(1), object(3)\n",
      "memory usage: 22.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "directory_path = 'C:/Data_MSc_Thesis/EC_Tower_Data/GPP_RECO_Rob'              # Specify the directory path\n",
    "files = os.listdir(directory_path)                                            # Get a list of all files and directories in the specified directory\n",
    "\n",
    "files = [f for f in files if os.path.isfile(os.path.join(directory_path, f))] # Filter out directories and only list files\n",
    "files_with_data = []                                                          # Initialize lists to store files with data and without data\n",
    "files_without_data = []\n",
    "data_list = []                                                                # Initialize an empty list to store the data\n",
    "\n",
    "# Loop through each file\n",
    "for file in files:\n",
    "    file_path = os.path.join(directory_path, file)\n",
    "    df = pd.read_csv(file_path, low_memory=False)                            # Read the CSV file with all columns\n",
    "    # Check if there is any data in the DataFrame\n",
    "    if not df.empty:\n",
    "        df['location'] = file                                                # Add the file name as a new column\n",
    "        data_list.append(df)                                                 # Append the full DataFrame to the list\n",
    "        files_with_data.append(file)\n",
    "    else:\n",
    "        files_without_data.append(file)                                      # If the file is empty, add it to files_without_data\n",
    "# Combine all data into a single DataFrame if there's any data\n",
    "if data_list:\n",
    "    GPP_RECO_df = pd.concat(data_list, ignore_index=True)                       # Combine all the data into a single DataFrame\n",
    "    print(\"Data successfully extracted!\")\n",
    "else:\n",
    "    print(\"No data available to merge.\")\n",
    "\n",
    "print(\"\\nFiles with data:\")\n",
    "print(files_with_data)\n",
    "print(\"\\nFiles without data:\")\n",
    "print(files_without_data)\n",
    "print(GPP_RECO_df.info()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33a828c4-8e47-409f-b9bb-fba67c0ec9b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>datetime</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>location</th>\n",
       "      <th>GPP_NT</th>\n",
       "      <th>RECO_NT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2022-01-05 00:00:00+01:00</td>\n",
       "      <td>2022-01-05 00:00:00+01:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ALB_MS_GPP_RECO.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-05 00:30:00+01:00</td>\n",
       "      <td>2022-01-05 00:00:00+01:00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>ALB_MS_GPP_RECO.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-01-05 01:00:00+01:00</td>\n",
       "      <td>2022-01-05 00:00:00+01:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ALB_MS_GPP_RECO.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2022-01-05 01:30:00+01:00</td>\n",
       "      <td>2022-01-05 00:00:00+01:00</td>\n",
       "      <td>1.5</td>\n",
       "      <td>ALB_MS_GPP_RECO.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2022-01-05 02:00:00+01:00</td>\n",
       "      <td>2022-01-05 00:00:00+01:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ALB_MS_GPP_RECO.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2022-01-05 02:30:00+01:00</td>\n",
       "      <td>2022-01-05 00:00:00+01:00</td>\n",
       "      <td>2.5</td>\n",
       "      <td>ALB_MS_GPP_RECO.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2022-01-05 03:00:00+01:00</td>\n",
       "      <td>2022-01-05 00:00:00+01:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>ALB_MS_GPP_RECO.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2022-01-05 03:30:00+01:00</td>\n",
       "      <td>2022-01-05 00:00:00+01:00</td>\n",
       "      <td>3.5</td>\n",
       "      <td>ALB_MS_GPP_RECO.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2022-01-05 04:00:00+01:00</td>\n",
       "      <td>2022-01-05 00:00:00+01:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>ALB_MS_GPP_RECO.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2022-01-05 04:30:00+01:00</td>\n",
       "      <td>2022-01-05 00:00:00+01:00</td>\n",
       "      <td>4.5</td>\n",
       "      <td>ALB_MS_GPP_RECO.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>2022-01-05 05:00:00+01:00</td>\n",
       "      <td>2022-01-05 00:00:00+01:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>ALB_MS_GPP_RECO.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>2022-01-05 05:30:00+01:00</td>\n",
       "      <td>2022-01-05 00:00:00+01:00</td>\n",
       "      <td>5.5</td>\n",
       "      <td>ALB_MS_GPP_RECO.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>2022-01-05 06:00:00+01:00</td>\n",
       "      <td>2022-01-05 00:00:00+01:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>ALB_MS_GPP_RECO.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>2022-01-05 06:30:00+01:00</td>\n",
       "      <td>2022-01-05 00:00:00+01:00</td>\n",
       "      <td>6.5</td>\n",
       "      <td>ALB_MS_GPP_RECO.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>2022-01-05 07:00:00+01:00</td>\n",
       "      <td>2022-01-05 00:00:00+01:00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>ALB_MS_GPP_RECO.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                   datetime                        day  hour  \\\n",
       "0            0  2022-01-05 00:00:00+01:00  2022-01-05 00:00:00+01:00   0.0   \n",
       "1            1  2022-01-05 00:30:00+01:00  2022-01-05 00:00:00+01:00   0.5   \n",
       "2            2  2022-01-05 01:00:00+01:00  2022-01-05 00:00:00+01:00   1.0   \n",
       "3            3  2022-01-05 01:30:00+01:00  2022-01-05 00:00:00+01:00   1.5   \n",
       "4            4  2022-01-05 02:00:00+01:00  2022-01-05 00:00:00+01:00   2.0   \n",
       "5            5  2022-01-05 02:30:00+01:00  2022-01-05 00:00:00+01:00   2.5   \n",
       "6            6  2022-01-05 03:00:00+01:00  2022-01-05 00:00:00+01:00   3.0   \n",
       "7            7  2022-01-05 03:30:00+01:00  2022-01-05 00:00:00+01:00   3.5   \n",
       "8            8  2022-01-05 04:00:00+01:00  2022-01-05 00:00:00+01:00   4.0   \n",
       "9            9  2022-01-05 04:30:00+01:00  2022-01-05 00:00:00+01:00   4.5   \n",
       "10          10  2022-01-05 05:00:00+01:00  2022-01-05 00:00:00+01:00   5.0   \n",
       "11          11  2022-01-05 05:30:00+01:00  2022-01-05 00:00:00+01:00   5.5   \n",
       "12          12  2022-01-05 06:00:00+01:00  2022-01-05 00:00:00+01:00   6.0   \n",
       "13          13  2022-01-05 06:30:00+01:00  2022-01-05 00:00:00+01:00   6.5   \n",
       "14          14  2022-01-05 07:00:00+01:00  2022-01-05 00:00:00+01:00   7.0   \n",
       "\n",
       "               location  GPP_NT  RECO_NT  \n",
       "0   ALB_MS_GPP_RECO.csv     NaN      NaN  \n",
       "1   ALB_MS_GPP_RECO.csv     NaN      NaN  \n",
       "2   ALB_MS_GPP_RECO.csv     NaN      NaN  \n",
       "3   ALB_MS_GPP_RECO.csv     NaN      NaN  \n",
       "4   ALB_MS_GPP_RECO.csv     NaN      NaN  \n",
       "5   ALB_MS_GPP_RECO.csv     NaN      NaN  \n",
       "6   ALB_MS_GPP_RECO.csv     NaN      NaN  \n",
       "7   ALB_MS_GPP_RECO.csv     NaN      NaN  \n",
       "8   ALB_MS_GPP_RECO.csv     NaN      NaN  \n",
       "9   ALB_MS_GPP_RECO.csv     NaN      NaN  \n",
       "10  ALB_MS_GPP_RECO.csv     NaN      NaN  \n",
       "11  ALB_MS_GPP_RECO.csv     NaN      NaN  \n",
       "12  ALB_MS_GPP_RECO.csv     NaN      NaN  \n",
       "13  ALB_MS_GPP_RECO.csv     NaN      NaN  \n",
       "14  ALB_MS_GPP_RECO.csv     NaN      NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPP_RECO_df.head(15)\n",
    "#GPP_RECO_df.tail(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ae748b-7941-4dbe-a8e2-06b1c96a3354",
   "metadata": {},
   "source": [
    "#### Dataframe pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a3d2404-95b6-4124-aef6-bae45a79891d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure datetime column is in the correct format first\n",
    "if pd.api.types.is_datetime64_any_dtype(GPP_RECO_df['datetime']):\n",
    "    GPP_RECO_df['datetime'] = GPP_RECO_df['datetime'].dt.tz_localize(None)\n",
    "else:\n",
    "    GPP_RECO_df['datetime'] = pd.to_datetime(GPP_RECO_df['datetime'], errors='coerce').dt.tz_localize(None)\n",
    "\n",
    "# Remove unecessary columns\n",
    "GPP_RECO_df = GPP_RECO_df.drop(columns=['Unnamed: 0','day'])\n",
    "GPP_RECO_df['date'] = GPP_RECO_df['datetime'].dt.date                             # Extract only the date part (removes time)\n",
    "GPP_RECO_df['location'] = GPP_RECO_df['location'].str.replace('_GPP_RECO.csv', '', regex=False)      \n",
    "GPP_RECO_df.rename(columns={\"location\": \"Source\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bc68a40-f1a5-428e-8375-dc0c880594ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 425510 entries, 0 to 425509\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count   Dtype         \n",
      "---  ------    --------------   -----         \n",
      " 0   datetime  425510 non-null  datetime64[ns]\n",
      " 1   hour      425510 non-null  float64       \n",
      " 2   Source    425510 non-null  object        \n",
      " 3   GPP_NT    372236 non-null  float64       \n",
      " 4   RECO_NT   424916 non-null  float64       \n",
      " 5   date      425510 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(3), object(2)\n",
      "memory usage: 19.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(GPP_RECO_df.info()) \n",
    "#GPP_RECO_df.head(15)\n",
    "#GPP_RECO_df.tail(15)\n",
    "#GPP_RECO_df.describe()\n",
    "\n",
    "#Check for Missing or Null Values\n",
    "#missing_values = GPP_RECO_df['datetime'].isnull().sum()\n",
    "#print(f\"Missing values: {missing_values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c30ed61-5a98-4f29-b5fa-285d71864a38",
   "metadata": {},
   "source": [
    "#### Import the complete dataset to merge the GPP_NT & RECO_NT   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb79b554-a014-4246-b596-a550f97aa9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load and preprocess data\n",
    "data_path = \"C:/Data_MSc_Thesis/Pre_Processed_Data_Final/Pre_Processed_Data_All_Locations_V1.csv\"\n",
    "complete_dataset = pd.read_csv(data_path, low_memory=False)\n",
    "complete_dataset['datetime'] = pd.to_datetime(complete_dataset['datetime'], errors='coerce', format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0186b77e-b562-4e3c-be02-5cec565b2595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 425308 entries, 0 to 425307\n",
      "Data columns (total 41 columns):\n",
      " #   Column      Non-Null Count   Dtype         \n",
      "---  ------      --------------   -----         \n",
      " 0   datetime    425299 non-null  datetime64[ns]\n",
      " 1   DOY         425200 non-null  object        \n",
      " 2   daytime     141704 non-null  object        \n",
      " 3   Source      425308 non-null  object        \n",
      " 4   SWCT_1_005  390173 non-null  float64       \n",
      " 5   SWCT_1_015  405102 non-null  float64       \n",
      " 6   SWCT_1_025  405250 non-null  float64       \n",
      " 7   SWCT_1_035  405140 non-null  float64       \n",
      " 8   SWCT_1_045  405447 non-null  float64       \n",
      " 9   SWCT_1_055  405289 non-null  float64       \n",
      " 10  SWCT_1_065  405442 non-null  float64       \n",
      " 11  SWCT_1_075  405565 non-null  float64       \n",
      " 12  SWCT_1_085  405564 non-null  float64       \n",
      " 13  SWCT_1_095  391620 non-null  float64       \n",
      " 14  SWCT_1_105  405528 non-null  float64       \n",
      " 15  SWCT_1_115  405570 non-null  float64       \n",
      " 16  STMP_1_005  391502 non-null  float64       \n",
      " 17  STMP_1_015  395243 non-null  float64       \n",
      " 18  STMP_1_025  392751 non-null  float64       \n",
      " 19  STMP_1_035  389116 non-null  float64       \n",
      " 20  STMP_1_045  390064 non-null  float64       \n",
      " 21  STMP_1_055  388415 non-null  float64       \n",
      " 22  STMP_1_065  391737 non-null  float64       \n",
      " 23  STMP_1_075  388028 non-null  float64       \n",
      " 24  STMP_1_085  385661 non-null  float64       \n",
      " 25  STMP_1_095  381062 non-null  float64       \n",
      " 26  STMP_1_105  388814 non-null  float64       \n",
      " 27  STMP_1_115  361586 non-null  float64       \n",
      " 28  WLEV_f      290698 non-null  float64       \n",
      " 29  WTMP_f      139395 non-null  float64       \n",
      " 30  ATMP_f      425191 non-null  float64       \n",
      " 31  PAIR_f      425191 non-null  float64       \n",
      " 32  WIND_f      425191 non-null  float64       \n",
      " 33  WINS_f      425191 non-null  float64       \n",
      " 34  RHUM_f      425191 non-null  float64       \n",
      " 35  RAIN_f      425191 non-null  float64       \n",
      " 36  VPD_f       417683 non-null  float64       \n",
      " 37  SWIN_f      425191 non-null  float64       \n",
      " 38  ET          136987 non-null  float64       \n",
      " 39  NEE_CO2     69301 non-null   float64       \n",
      " 40  NEE_CH4     13849 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(37), object(3)\n",
      "memory usage: 133.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(complete_dataset.info()) \n",
    "#complete_dataset.head(15)\n",
    "#complete_dataset.tail(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4a97bd-4ea7-4261-b9a6-c585604d5c6c",
   "metadata": {},
   "source": [
    "#### Merge the two dataframes based on 'datetime' and 'Source'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4011f89c-3b87-4eee-b86d-1b2d973385b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge only the GPP_NT and RECO_NT columns based on datetime and Source\n",
    "merged_df = complete_dataset.merge(\n",
    "    GPP_RECO_df[['datetime', 'Source', 'GPP_NT', 'RECO_NT']], \n",
    "    on=['datetime', 'Source'], \n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a991b4e-65e0-4094-a9bb-5317ee0e760c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 425308 entries, 0 to 425307\n",
      "Data columns (total 43 columns):\n",
      " #   Column      Non-Null Count   Dtype         \n",
      "---  ------      --------------   -----         \n",
      " 0   datetime    425299 non-null  datetime64[ns]\n",
      " 1   DOY         425200 non-null  object        \n",
      " 2   daytime     141704 non-null  object        \n",
      " 3   Source      425308 non-null  object        \n",
      " 4   SWCT_1_005  390173 non-null  float64       \n",
      " 5   SWCT_1_015  405102 non-null  float64       \n",
      " 6   SWCT_1_025  405250 non-null  float64       \n",
      " 7   SWCT_1_035  405140 non-null  float64       \n",
      " 8   SWCT_1_045  405447 non-null  float64       \n",
      " 9   SWCT_1_055  405289 non-null  float64       \n",
      " 10  SWCT_1_065  405442 non-null  float64       \n",
      " 11  SWCT_1_075  405565 non-null  float64       \n",
      " 12  SWCT_1_085  405564 non-null  float64       \n",
      " 13  SWCT_1_095  391620 non-null  float64       \n",
      " 14  SWCT_1_105  405528 non-null  float64       \n",
      " 15  SWCT_1_115  405570 non-null  float64       \n",
      " 16  STMP_1_005  391502 non-null  float64       \n",
      " 17  STMP_1_015  395243 non-null  float64       \n",
      " 18  STMP_1_025  392751 non-null  float64       \n",
      " 19  STMP_1_035  389116 non-null  float64       \n",
      " 20  STMP_1_045  390064 non-null  float64       \n",
      " 21  STMP_1_055  388415 non-null  float64       \n",
      " 22  STMP_1_065  391737 non-null  float64       \n",
      " 23  STMP_1_075  388028 non-null  float64       \n",
      " 24  STMP_1_085  385661 non-null  float64       \n",
      " 25  STMP_1_095  381062 non-null  float64       \n",
      " 26  STMP_1_105  388814 non-null  float64       \n",
      " 27  STMP_1_115  361586 non-null  float64       \n",
      " 28  WLEV_f      290698 non-null  float64       \n",
      " 29  WTMP_f      139395 non-null  float64       \n",
      " 30  ATMP_f      425191 non-null  float64       \n",
      " 31  PAIR_f      425191 non-null  float64       \n",
      " 32  WIND_f      425191 non-null  float64       \n",
      " 33  WINS_f      425191 non-null  float64       \n",
      " 34  RHUM_f      425191 non-null  float64       \n",
      " 35  RAIN_f      425191 non-null  float64       \n",
      " 36  VPD_f       417683 non-null  float64       \n",
      " 37  SWIN_f      425191 non-null  float64       \n",
      " 38  ET          136987 non-null  float64       \n",
      " 39  NEE_CO2     69301 non-null   float64       \n",
      " 40  NEE_CH4     13849 non-null   float64       \n",
      " 41  GPP_NT      372314 non-null  float64       \n",
      " 42  RECO_NT     425010 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(39), object(3)\n",
      "memory usage: 139.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.info()) \n",
    "#merged_df.head(15)\n",
    "#merged_df.tail(15)\n",
    "#merged_df.dtypes\n",
    "#merged_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac05103b-7567-4b15-8970-939202f707dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              GPP_NT        RECO_NT\n",
      "count  372314.000000  425010.000000\n",
      "mean        6.263830       6.154915\n",
      "std         9.801603       3.904230\n",
      "min       -48.126830       0.424153\n",
      "25%        -0.070678       2.822918\n",
      "50%         1.689503       5.247238\n",
      "75%        10.602459       8.944092\n",
      "max        60.494108      27.719204\n"
     ]
    }
   ],
   "source": [
    "columns_of_interest = ['GPP_NT', 'RECO_NT']  \n",
    "print(merged_df[columns_of_interest].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b10cc8e-415d-4cfa-8aba-ab51ded19914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame successfully saved to C:/Data_MSc_Thesis/Pre_Processed_Data_Final/Pre_Processed_Data_All_Locations_V2.csv\n"
     ]
    }
   ],
   "source": [
    "# Export the final dataframe to a CSV file\n",
    "output_path = \"C:/Data_MSc_Thesis/Pre_Processed_Data_Final/Pre_Processed_Data_All_Locations_V2.csv\"  # Update the path as needed\n",
    "merged_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"DataFrame successfully saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
