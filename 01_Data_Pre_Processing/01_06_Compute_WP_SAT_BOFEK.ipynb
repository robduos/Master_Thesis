{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da7e0bdd-e996-4e19-a4a4-ca17237e8c33",
   "metadata": {},
   "source": [
    "**Script Description:** This script calculates key soil hydraulic properties (Wilting Point, Saturation, Porosity) using the BOFEK2020 methodology and source data. It loads site data containing BOFEK2020 unit assignments, maps these units to their dominant soil profiles using the official BOFEK2020 results table, retrieves the layer structure for these profiles, looks up the corresponding Staringreeks 2018 Mualem-Van Genuchten parameters, calculates the hydraulic properties per layer, and finally aggregates or selects these properties based on a user-defined target depth or interval.\n",
    "\n",
    "**File Name:** 01_06_Extract_BOFEK_Data.ipynb\n",
    "\n",
    "**Date:** 2025\n",
    "\n",
    "**Created by:** Rob Alamgir\n",
    "\n",
    "**References:**\n",
    "\n",
    "   [1] Heinen, M., Brouwer, F., Teuling, K., Walvoort, D. (2021).\n",
    "       BOFEK2020 - Soil physical schematization of the Netherlands; Update soil physical unit map.\n",
    "       Wageningen Environmental Research, Report 3056.\n",
    "       DOI: https://doi.org/10.18174/541544     [cite: 1]\n",
    "\n",
    "   [2] Heinen, M., Bakker, G., WÃ¶sten, H. (2020).\n",
    "       Water retention and permeability characteristics of tops and subsurfaces in the Netherlands: the Staring series; update 2018.\n",
    "       Wageningen Environmental Research, Report 2978.\n",
    "       (Referenced in BOFEK2020 report [cite: 1, page 36])\n",
    "\n",
    "   [3] BOFEK2020 Data Download:\n",
    "       Wageningen University & Research. Bodemfysische Eenhedenkaart (BOFEK2020).\n",
    "       Retrieved from: https://www.wur.nl/nl/show/Bodemphysical-Eenhedenkaart-BOFEK2020.htm [cite: 1, pages 10, 34]\n",
    "\n",
    "   [4] Van Genuchten, M.Th. (1980).\n",
    "       A closed-form equation for predicting the hydraulic conductivity of unsaturated soils.\n",
    "       Soil Science Society of America Journal 44(3): 892-898.\n",
    "       (Referenced in BOFEK2020 report [cite: 1, page 36])\n",
    "\n",
    "   [5] Mualem, Y. (1976).\n",
    "       A new model for predicting the hydraulic conductivity of unsaturated porous media.\n",
    "       Water Resources Research, 12: 513-522.\n",
    "       (Referenced in BOFEK2020 report [cite: 1, page 36])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f652cb-e596-442d-963c-fedd8bffb37b",
   "metadata": {},
   "source": [
    "#### Import the relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97189109-0b37-4562-bb03-1f05043b96ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9829576-4790-471a-a7a7-d596ba47f5f4",
   "metadata": {},
   "source": [
    "#### Import all the relevant datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fd2bc1f-0608-44d7-8724-e7ceba428b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOBV_Soil_Data_CSV_data_path = \"C:/Data_MSc_Thesis/NOBV_Site_Data/NOBV_Soil_Data_CSV.csv\"\n",
    "NOBV_Soil_Data_CSV = pd.read_csv(NOBV_Soil_Data_CSV_data_path, encoding='ISO-8859-1')\n",
    "#NOBV_Soil_Data_CSV.info(verbose=True)\n",
    "#NOBV_Soil_Data_CSV.head(22)\n",
    "\n",
    "all_results_formatted_95_data_path = \"C:/Data_MSc_Thesis/BOFEK/3_Clustering/Output/all_results_formatted_95.csv\"\n",
    "all_results_formatted_95 = pd.read_csv(all_results_formatted_95_data_path)\n",
    "#all_results_formatted_95.info(verbose=True)\n",
    "#all_results_formatted_95.head(10)\n",
    "\n",
    "AllProfiles_368_data_path = \"C:/Data_MSc_Thesis/BOFEK/1_CalcAllPars/Data/AllProfiles_368.csv\"\n",
    "AllProfiles_368 = pd.read_csv(AllProfiles_368_data_path)\n",
    "#AllProfiles_368.info(verbose=True)\n",
    "#AllProfiles_368.head(10)\n",
    "\n",
    "StaringReeksPARS_2018_data_path = \"C:/Data_MSc_Thesis/BOFEK/1_CalcAllPars/Data/StaringReeksPARS_2018.csv\"\n",
    "StaringReeksPARS_2018 = pd.read_csv(StaringReeksPARS_2018_data_path)\n",
    "#StaringReeksPARS_2018.info(verbose=True)\n",
    "#StaringReeksPARS_2018.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df13ece6-a62e-45d9-b09c-95230843e18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "#data_path = \"C:/Data_MSc_Thesis/BOFEK/1_CalcAllPars/Output/OUT_AllProfiles_ALL.csv\"\n",
    "#OUT_AllProfiles_ALL = pd.read_csv(data_path)\n",
    "##OUT_AllProfiles_ALL.info(verbose=True)\n",
    "#OUT_AllProfiles_ALL.head(10)\n",
    "\n",
    "# Load and preprocess data\n",
    "#data_path = \"C:/Data_MSc_Thesis/BOFEK/1_CalcAllPars/Output/profile_info.csv\"\n",
    "#profile_info = pd.read_csv(data_path)\n",
    "##profile_info.info(verbose=True)\n",
    "#profile_info.head(10)\n",
    "\n",
    "# Load and preprocess data\n",
    "#data_path = \"C:/Data_MSc_Thesis/BOFEK/3_Clustering/Data/BodemCode.csv\"\n",
    "#BodemCode = pd.read_csv(data_path)\n",
    "##BodemCode.info(verbose=True)\n",
    "#BodemCode.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e621c78-e6e0-45bd-bf00-58e9eb74ea23",
   "metadata": {},
   "source": [
    "#### Specify DataFrame variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48a078ed-1f07-4de3-88d6-a83697e4f004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating for specific depth: 5.0 cm\n"
     ]
    }
   ],
   "source": [
    "sites_df = NOBV_Soil_Data_CSV                # DataFrame from your site list CSV\n",
    "bofek_results_df = all_results_formatted_95  # DataFrame from all_results_formatted_95.csv\n",
    "profiles_df = AllProfiles_368                # DataFrame from AllProfiles_368.csv\n",
    "staring_df = StaringReeksPARS_2018           # DataFrame from StaringReeksPARS_2018.csv\n",
    "\n",
    "# From NOBV_Soil_Data_CSV\n",
    "site_id_col = 'Site_ID'\n",
    "bofek_unit_col = 'BOFEK_2020_Physical Units'\n",
    "\n",
    "# From all_results_formatted_95 \n",
    "bofek_profile_id_col = 'iProfile'\n",
    "bofek_cluster_col = 'clust1'    # BOFEK Unit number\n",
    "bofek_dominant_col = 'dominant' # Flag for dominant profile (value=1)\n",
    "\n",
    "profiles_profile_id_col = 'iProfile' # From AllProfiles_368 \n",
    "\n",
    "# From StaringReeksPARS_2018\n",
    "staring_id_col = 'StaringID'\n",
    "staring_theta_r_col = 'theta_r'\n",
    "staring_theta_s_col = 'theta_s'\n",
    "staring_alpha_col = 'alpha'\n",
    "staring_n_col = 'n'\n",
    "\n",
    "# Define Constants\n",
    "target_depth_cm = 5.0  # Target Depth\n",
    "use_interval = False\n",
    "print(f\"Calculating for specific depth: {target_depth_cm} cm\")\n",
    "h_wp = -16000.0        # Pressure head for Wilting Point in cm [cite: 1, page 17]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35efe378-9295-460e-b3a0-74d758d1c305",
   "metadata": {},
   "source": [
    "### Step 1: Rename Staring dataframe Columns (Matching .head() output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc2c79f3-b467-4e88-9115-357d9b0c2ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed Staring DF columns successfully.\n"
     ]
    }
   ],
   "source": [
    "# Use the exact column names from your StaringReeksPARS_2018.head() output\n",
    "# as the keys in the dictionary, mapping them to the target names used later.\n",
    "try:\n",
    "    staring_df.rename(columns={\n",
    "        'i': staring_id_col,        # Original column 'i'\n",
    "        'WCr': staring_theta_r_col, # Original column 'WCr'\n",
    "        'WCs': staring_theta_s_col, # Original column 'WCs'\n",
    "        'Alpha': staring_alpha_col, # Original column 'Alpha'\n",
    "        'Npar': staring_n_col       # Original column 'Npar'\n",
    "        # Add 'Lambda': 'lambda', 'Ksfit': 'ksat' if needed\n",
    "    }, inplace=True, errors='raise') # Use 'raise' to catch errors if columns don't exist\n",
    "    print(\"Renamed Staring DF columns successfully.\")\n",
    "except KeyError as e:\n",
    "    print(f\"Error renaming Staring DF columns: Column '{e}' not found.\")\n",
    "    print(\"Please ensure staring_df is loaded and original column names are exactly 'i', 'WCr', 'WCs', 'Alpha', 'Npar'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc75b18-47df-4f5a-bae9-a7bf761c3839",
   "metadata": {},
   "source": [
    "### Step 2: Create BOFEK Unit -> Dominant Profile Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78cfcd49-9f01-436f-9ea5-2a31e2fc6b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created map for 79 dominant profiles.\n"
     ]
    }
   ],
   "source": [
    "dominant_profile_map = {} # Initialize empty map\n",
    "try:\n",
    "    # Filter bofek_results_df to get only the dominant profiles (dominant == 1)\n",
    "    dominant_profiles = bofek_results_df[bofek_results_df[bofek_dominant_col] == 1].copy()\n",
    "\n",
    "    # Create the mapping dictionary {BOFEK_Unit : dominant_iProfile}\n",
    "    dominant_profile_map = pd.Series(\n",
    "        dominant_profiles[bofek_profile_id_col].values,\n",
    "        index=dominant_profiles[bofek_cluster_col] # BOFEK unit number\n",
    "    ).to_dict()\n",
    "    print(f\"Created map for {len(dominant_profile_map)} dominant profiles.\")\n",
    "    if not dominant_profile_map:\n",
    "         print(\"Warning: Dominant profile map is empty. Check 'dominant' column in bofek_results_df.\")\n",
    "except KeyError as e:\n",
    "    print(f\"Error creating dominant profile map: Column '{e}' not found in bofek_results_df.\")\n",
    "    print(\"Please ensure columns are named correctly ('iProfile', 'clust1', 'dominant').\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred creating the dominant profile map: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5639b2c1-16a4-4370-ac8c-47045745cc52",
   "metadata": {},
   "source": [
    "### Step 3: Add Dominant Profile ID to the Site Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d72cddc6-0ec4-4830-8d50-4d3a0e18a86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the new column name clearly\n",
    "dominant_profile_id_col = 'Dominant_iProfile' # Explicit name for clarity\n",
    "if dominant_profile_map:                      # Proceed only if map was created\n",
    "    sites_df[dominant_profile_id_col] = sites_df[bofek_unit_col].map(dominant_profile_map)\n",
    "    # Check for mapping issues\n",
    "    if sites_df[dominant_profile_id_col].isnull().any():\n",
    "        print(\"\\nWarning: Some sites could not be mapped to a dominant profile!\")\n",
    "        print(\"Check the BOFEK units in your site data and the dominant profile map.\")\n",
    "        # Show only sites with missing dominant profile IDs\n",
    "        print(sites_df[sites_df[dominant_profile_id_col].isnull()][[site_id_col, bofek_unit_col]])\n",
    "else:\n",
    "    print(\"\\nError: Cannot map dominant profiles. Dominant profile map is empty or invalid.\")\n",
    "    sites_df[dominant_profile_id_col] = np.nan # Add column but fill with NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e7ab2c-2a30-490b-b098-e84787e3794b",
   "metadata": {},
   "source": [
    "### Step 4: Define Calculation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a947352-0b84-4e6c-a469-4a7211b4d97b",
   "metadata": {},
   "source": [
    "$$ \\theta(h) = \\theta_r + \\frac{\\theta_s - \\theta_r}{ \\left[ 1 + (|\\alpha h|)^n \\right]^{1 - 1/n} } $$\n",
    "\n",
    "Reminder: This formula applies when the soil is unsaturated (h < 0). If the soil is saturated (h â¥ 0), the formula simplifies to: Î¸(h) = Î¸s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d1261c1-38f7-41fd-92f4-958a8395590a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pressure head (h)\n",
    "# soil water content (theta)\n",
    "# saturated water content (theta_s , Î¸s)\n",
    "# residual water content (theta_r, Î¸r)\n",
    "# van Genuchten parameters (alpha, n) as input.\n",
    "# Î± (alpha)  van Genuchten parameter related to air entry pressure (units of 1/Length).\n",
    "# n is the van Genuchten parameter related to pore size distribution (dimensionless, n > 1).\n",
    "\n",
    "def calculate_theta(h, theta_s, theta_r, alpha, n):\n",
    "    \"\"\"Calculates water content theta using Mualem-Van Genuchten.\"\"\"\n",
    "    \n",
    "    # Input validation by checking if any of the input values are NaN\n",
    "    if pd.isna(h) or pd.isna(theta_s) or pd.isna(theta_r) or pd.isna(alpha) or pd.isna(n):\n",
    "        return np.nan\n",
    "    \n",
    "    # parameter n must be greater than 1 for the model to be physically realistic and \n",
    "    # mathematically well-behaved (specifically, it ensures m = 1 - 1/n is positive). Returns NaN if n is invalid.   \n",
    "    if n <= 1.0:\n",
    "        return np.nan \n",
    "    \n",
    "    # saturated water content (theta_s) cannot be less than residual water content, physically impossible  \n",
    "    if theta_s < theta_r:\n",
    "        return np.nan \n",
    "\n",
    "    # Handles the saturated or positive pressure case. If the pressure head h is zero or positive, \n",
    "    # the soil is assumed fully saturated, and the water content is simply theta_s.\n",
    "    if h >= 0:\n",
    "        return theta_s \n",
    "    \n",
    "    # Calculates the dependent parameter m based on n, according to the standard constraint often used with the Mualem model.\n",
    "    m = 1.0 - (1.0 / n)\n",
    "    \n",
    "    # Mathematically, if alpha is 0, the term (|Î±h|)â¿ is 0 (for h<0), the denominator [1+0]áµ is 1, and theta should equal theta_s.\n",
    "    if alpha == 0:\n",
    "        return theta_r # Limit case as pressure becomes very negative\n",
    "\n",
    "    try:\n",
    "        # block to catch potential numerical errors (like numbers becoming too large or small, or invalid operations)\n",
    "        \n",
    "        # Calculates the base term |Î±h|. np.abs ensures it's positive since h is negative in this part of the code.\n",
    "        term_base = np.abs(alpha * h)\n",
    "        # Overflow Prevention: This cleverly checks if calculating term_base**n would likely result in an overflow error \n",
    "        # before actually doing the calculation. np.exp(700) is roughly the largest number a standard float can hold. \n",
    "        # If log(term_base^n) (which equals n * log(term_base)) exceeds 700, the result of the exponentiation would be too large. \n",
    "        # In this limit (corresponding to very large negative h, i.e., very dry soil), theta approaches theta_r.\n",
    "        if n * np.log(term_base) > 700:\n",
    "             return theta_r\n",
    "        \n",
    "        # Calculates 1 + (|Î±h|)â¿. It then checks if the result (term) is finite and positive.\n",
    "        term = 1.0 + np.power(term_base, n)\n",
    "        if not np.isfinite(term) or term <= 0:\n",
    "            return np.nan\n",
    "\n",
    "        # Check power m\n",
    "        if m * np.log(term) < -700: # Avoid underflow leading to division by zero\n",
    "             return theta_s # Denominator is ~0, fraction is huge, approaches theta_s (incorrect limit?) -> better NaN? Let's try NaN.\n",
    "             # Actually, if denominator -> 0, term is huge, theta -> theta_r.\n",
    "             # Let's rethink: If term**m -> 0, then theta -> theta_r + (theta_s - theta_r) / 0 -> Inf?\n",
    "             # If h-> -inf, term_base -> inf, term -> inf, term**m -> inf (assuming m>0), denom -> inf, frac -> 0, theta -> theta_r.\n",
    "             # Let's trust the formula limit. If term**m results in 0 or non-finite, it's likely an issue.\n",
    "             return theta_r # If denominator is effectively zero due to underflow\n",
    "            \n",
    "        # Calculates the full denominator [ 1 + (|Î±h|)â¿ ]áµ. \n",
    "        # Checks again if the result is finite and non-zero to prevent division by zero.\n",
    "        denominator = np.power(term, m)\n",
    "        if not np.isfinite(denominator) or denominator == 0:\n",
    "            return np.nan \n",
    "\n",
    "        # Calculates the final theta value using the rearranged van Genuchten formula.\n",
    "        theta = theta_r + (theta_s - theta_r) / denominator\n",
    "\n",
    "        # Final Bounds Check: Checks if the calculated theta is within the physical bounds (theta_r to theta_s), \n",
    "        # allowing for a tiny numerical tolerance (1e-6). Instead of forcing the value into the bounds (clamping), \n",
    "        # it returns NaN, indicating that something potentially went wrong in the calculation if the result is outside the expected physical range.\n",
    "        if theta < theta_r - 1e-6 or theta > theta_s + 1e-6:\n",
    "            # print(f\"  Debug: Calculated theta {theta} outside bounds ({theta_r=}, {theta_s=})\")\n",
    "            return np.nan\n",
    "        return theta # If all calculations are successful and checks pass, the final calculated theta value is returned.\n",
    "\n",
    "    except (OverflowError, ValueError, RuntimeWarning) as e: # Catch more numeric issues\n",
    "        # print(f\"  Debug: Numeric exception in calculate_theta ({e})\")\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b56c75-a1ce-4098-8531-c062b27af4e0",
   "metadata": {},
   "source": [
    "### Step 5: Process Each Site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92e0912c-9aec-4fc3-96c4-ebca0c4bf840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Sites ---\n",
      "Processing Site: ALB_MS (Profile: 1130) - Calculating...\n",
      "Processing Site: ALB_RF (Profile: 1130) - Using cached results\n",
      "Processing Site: AMM (Profile: 1281) - Calculating...\n",
      "Processing Site: AMR (Profile: 1281) - Using cached results\n",
      "Processing Site: ANK_PT (Profile: 1281) - Using cached results\n",
      "Processing Site: ASD_MP (Profile: 1050) - Calculating...\n",
      "Processing Site: BUO (Profile: 1170) - Calculating...\n",
      "Processing Site: BUW (Profile: 15130) - Calculating...\n",
      "Processing Site: CAM (Profile: 1050) - Using cached results\n",
      "Processing Site: DEM (Profile: 1050) - Using cached results\n",
      "Processing Site: HOC (Profile: 1200) - Calculating...\n",
      "Processing Site: HOH (Profile: 1200) - Using cached results\n",
      "Processing Site: ILP_PT (Profile: 1281) - Using cached results\n",
      "Processing Site: LAW_MOB (Profile: 1130) - Using cached results\n",
      "Processing Site: LAW_MS (Profile: 1130) - Using cached results\n",
      "Processing Site: LDC (Profile: 1281) - Using cached results\n",
      "Processing Site: LDH (Profile: 1281) - Using cached results\n",
      "Processing Site: ONL (Profile: 1050) - Using cached results\n",
      "Processing Site: WRW_SR (Profile: 1281) - Using cached results\n",
      "Processing Site: ZEG_MOB (Profile: 1130) - Using cached results\n",
      "Processing Site: ZEG_PT (Profile: 1130) - Using cached results\n"
     ]
    }
   ],
   "source": [
    "results = []                  # Creates an empty list to store the final calculated properties for each site.\n",
    "processed_profiles_cache = {} # Cache results {profile_id: {'WP': wp, 'SAT': sat, 'Porosity': poro}}\n",
    "\n",
    "print(\"\\n--- Processing Sites ---\")\n",
    "for index, site_row in sites_df.iterrows():\n",
    "    site_id = site_row[site_id_col]\n",
    "    profile_id = site_row[dominant_profile_id_col] # Use the mapped dominant profile ID\n",
    "\n",
    "    # Initialize results for this site\n",
    "    site_result_wp = np.nan\n",
    "    site_result_sat = np.nan\n",
    "    site_result_porosity = np.nan\n",
    "\n",
    "    if pd.isna(profile_id):\n",
    "        print(f\"Skipping site {site_id}: No dominant profile mapped.\")\n",
    "        results.append({'Site_ID': site_id, 'WP': site_result_wp, 'SAT': site_result_sat, 'Porosity': site_result_porosity})\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        profile_id_int = int(profile_id)\n",
    "    except ValueError:\n",
    "        print(f\"Skipping site {site_id}: Invalid dominant profile ID '{profile_id}'.\")\n",
    "        results.append({'Site_ID': site_id, 'WP': site_result_wp, 'SAT': site_result_sat, 'Porosity': site_result_porosity})\n",
    "        continue\n",
    "\n",
    "    # Check cache first\n",
    "    if profile_id_int in processed_profiles_cache:\n",
    "        cached_result = processed_profiles_cache[profile_id_int]\n",
    "        site_result_wp = cached_result['WP']\n",
    "        site_result_sat = cached_result['SAT']\n",
    "        site_result_porosity = cached_result['Porosity']\n",
    "        print(f\"Processing Site: {site_id} (Profile: {profile_id_int}) - Using cached results\")\n",
    "        results.append({'Site_ID': site_id, 'WP': site_result_wp, 'SAT': site_result_sat, 'Porosity': site_result_porosity})\n",
    "        continue # Move to next site\n",
    "\n",
    "    # Process Profile (if not cached) \n",
    "    print(f\"Processing Site: {site_id} (Profile: {profile_id_int}) - Calculating...\")\n",
    "    profile_structure = profiles_df[profiles_df[profiles_profile_id_col] == profile_id_int]\n",
    "\n",
    "    if profile_structure.empty:\n",
    "        print(f\"  Error: Profile structure for iProfile {profile_id_int} not found.\")\n",
    "        # Store NaN in cache for this profile ID to avoid repeated lookups\n",
    "        processed_profiles_cache[profile_id_int] = {'WP': np.nan, 'SAT': np.nan, 'Porosity': np.nan}\n",
    "        results.append({'Site_ID': site_id, 'WP': site_result_wp, 'SAT': site_result_sat, 'Porosity': site_result_porosity})\n",
    "        continue\n",
    "\n",
    "    # Extract layers and calculate layer properties \n",
    "    layer_results_list = []\n",
    "    last_depth = 0.0\n",
    "    valid_layers_found_structure = False\n",
    "    for i in range(1, 10): # Max 9 layers\n",
    "        soil_col = f'iSoil{i}'\n",
    "        depth_col = f'iZ{i}'\n",
    "        if soil_col not in profile_structure.columns or depth_col not in profile_structure.columns: break\n",
    "\n",
    "        staring_id_val = profile_structure.iloc[0][soil_col]\n",
    "        bottom_depth_val = profile_structure.iloc[0][depth_col]\n",
    "\n",
    "        # Check for termination conditions or NaN Staring ID\n",
    "        if pd.isna(staring_id_val) or staring_id_val <= 0 or bottom_depth_val > 9999: break\n",
    "\n",
    "        top_depth_val = last_depth\n",
    "        thickness_val = bottom_depth_val - top_depth_val\n",
    "\n",
    "        if thickness_val <= 1e-6: # Use tolerance for thickness check\n",
    "             # print(f\"  Warning: Near-zero layer thickness ({thickness_val}cm) for layer {i} in profile {profile_id_int}.\")\n",
    "             last_depth = bottom_depth_val # Still update depth\n",
    "             continue\n",
    "\n",
    "        valid_layers_found_structure = True\n",
    "        current_staring_id = int(staring_id_val)\n",
    "\n",
    "        # Lookup parameters\n",
    "        params = staring_df[staring_df[staring_id_col] == current_staring_id]\n",
    "        if params.empty:\n",
    "            print(f\"    Warning: Parameters for StaringID {current_staring_id} (Layer {i}) not found.\")\n",
    "            layer_wp_val, layer_sat_val, layer_porosity_val = np.nan, np.nan, np.nan\n",
    "        else:\n",
    "            param_row = params.iloc[0]\n",
    "            theta_s = param_row[staring_theta_s_col]\n",
    "            theta_r = param_row[staring_theta_r_col]\n",
    "            alpha = param_row[staring_alpha_col]\n",
    "            n = param_row[staring_n_col]\n",
    "\n",
    "            layer_sat_val = theta_s\n",
    "            layer_porosity_val = theta_s # Porosity = theta_s\n",
    "            layer_wp_val = calculate_theta(h_wp, theta_s, theta_r, alpha, n)\n",
    "\n",
    "        layer_results_list.append({\n",
    "            'WP': layer_wp_val, 'SAT': layer_sat_val, 'Porosity': layer_porosity_val,\n",
    "            'Top': top_depth_val, 'Bottom': bottom_depth_val, 'Thickness': thickness_val\n",
    "        })\n",
    "        last_depth = bottom_depth_val\n",
    "        if last_depth >= 120.0 - 1e-6: break # Stop if profile depth reaches ~120 cm\n",
    "\n",
    "    # Aggregate/Select for Target Depth \n",
    "    if not valid_layers_found_structure:\n",
    "        print(f\"  Error: No valid layers extracted for profile {profile_id_int}.\")\n",
    "        # Store NaN in cache\n",
    "        processed_profiles_cache[profile_id_int] = {'WP': np.nan, 'SAT': np.nan, 'Porosity': np.nan}\n",
    "        results.append({'Site_ID': site_id, 'WP': np.nan, 'SAT': np.nan, 'Porosity': np.nan})\n",
    "        continue\n",
    "\n",
    "    # Perform aggregation/selection based on layer_results_list\n",
    "    if use_interval:\n",
    "        interval_top, interval_bottom = target_interval_cm\n",
    "        total_thickness_in_interval = 0.0\n",
    "        weighted_wp_sum = 0.0\n",
    "        weighted_sat_sum = 0.0\n",
    "        weighted_porosity_sum = 0.0\n",
    "        valid_data_found = False\n",
    "        for res in layer_results_list:\n",
    "            overlap_top = max(res['Top'], interval_top)\n",
    "            overlap_bottom = min(res['Bottom'], interval_bottom)\n",
    "            overlap_thickness = max(0.0, overlap_bottom - overlap_top)\n",
    "            if overlap_thickness > 1e-6:\n",
    "                if not pd.isna(res['WP']) and not pd.isna(res['SAT']) and not pd.isna(res['Porosity']):\n",
    "                    total_thickness_in_interval += overlap_thickness\n",
    "                    weighted_wp_sum += res['WP'] * overlap_thickness\n",
    "                    weighted_sat_sum += res['SAT'] * overlap_thickness\n",
    "                    weighted_porosity_sum += res['Porosity'] * overlap_thickness\n",
    "                    valid_data_found = True\n",
    "        if valid_data_found and total_thickness_in_interval > 1e-6:\n",
    "            site_result_wp = weighted_wp_sum / total_thickness_in_interval\n",
    "            site_result_sat = weighted_sat_sum / total_thickness_in_interval\n",
    "            site_result_porosity = weighted_porosity_sum / total_thickness_in_interval\n",
    "        else:\n",
    "            print(f\"  Warning: No valid layers with data found within target interval {target_interval_cm} for profile {profile_id_int}\")\n",
    "    else: # Specific depth\n",
    "        layer_found = False\n",
    "        for res in layer_results_list:\n",
    "            if res['Top'] <= target_depth_cm + 1e-6 and target_depth_cm < res['Bottom'] - 1e-6 :\n",
    "                site_result_wp = res['WP']\n",
    "                site_result_sat = res['SAT']\n",
    "                site_result_porosity = res['Porosity']\n",
    "                layer_found = True\n",
    "                if pd.isna(site_result_wp) or pd.isna(site_result_sat) or pd.isna(site_result_porosity):\n",
    "                     print(f\"    Info: Target depth {target_depth_cm}cm found in layer Top={res['Top']:.1f}-Bottom={res['Bottom']:.1f}, but calculated WP/SAT/Porosity is NaN.\")\n",
    "                break\n",
    "        if not layer_found:\n",
    "             print(f\"  Warning: Target depth {target_depth_cm}cm not found within any valid layer range for profile {profile_id_int}\")\n",
    "\n",
    "    # Store results for this site and add to cache\n",
    "    results.append({\n",
    "        'Site_ID': site_id,\n",
    "        'WP': site_result_wp,\n",
    "        'SAT': site_result_sat,\n",
    "        'Porosity': site_result_porosity\n",
    "    })\n",
    "    processed_profiles_cache[profile_id_int] = {\n",
    "        'WP': site_result_wp,\n",
    "        'SAT': site_result_sat,\n",
    "        'Porosity': site_result_porosity\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73f08dd-f983-43c5-9995-77e995d0fdd0",
   "metadata": {},
   "source": [
    "### Step 6: Combine results to the original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2f9d1e9-586b-4a1b-940e-9761ec6ff743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site_ID</th>\n",
       "      <th>Site_Name</th>\n",
       "      <th>Province</th>\n",
       "      <th>BOFEK_2020_Physical Units</th>\n",
       "      <th>Peat_Thickness_2022</th>\n",
       "      <th>Dominant_iProfile</th>\n",
       "      <th>WP</th>\n",
       "      <th>SAT</th>\n",
       "      <th>Porosity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALB_MS</td>\n",
       "      <td>Aldeboam North</td>\n",
       "      <td>FryslÃ¢n</td>\n",
       "      <td>1018</td>\n",
       "      <td>143.750000</td>\n",
       "      <td>1130</td>\n",
       "      <td>0.328796</td>\n",
       "      <td>0.718626</td>\n",
       "      <td>0.718626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALB_RF</td>\n",
       "      <td>Aldeboam North</td>\n",
       "      <td>FryslÃ¢n</td>\n",
       "      <td>1018</td>\n",
       "      <td>143.250000</td>\n",
       "      <td>1130</td>\n",
       "      <td>0.328796</td>\n",
       "      <td>0.718626</td>\n",
       "      <td>0.718626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMM</td>\n",
       "      <td>Aldeboam Maize</td>\n",
       "      <td>FryslÃ¢n</td>\n",
       "      <td>1006</td>\n",
       "      <td>193.500000</td>\n",
       "      <td>1281</td>\n",
       "      <td>0.319729</td>\n",
       "      <td>0.765452</td>\n",
       "      <td>0.765452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMR</td>\n",
       "      <td>Aldeboam Maize</td>\n",
       "      <td>FryslÃ¢n</td>\n",
       "      <td>1006</td>\n",
       "      <td>184.500000</td>\n",
       "      <td>1281</td>\n",
       "      <td>0.319729</td>\n",
       "      <td>0.765452</td>\n",
       "      <td>0.765452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANK_PT</td>\n",
       "      <td>Ankeveen</td>\n",
       "      <td>Noord-Holland</td>\n",
       "      <td>1006</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1281</td>\n",
       "      <td>0.319729</td>\n",
       "      <td>0.765452</td>\n",
       "      <td>0.765452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASD_MP</td>\n",
       "      <td>Assendelft</td>\n",
       "      <td>Noord-Holland</td>\n",
       "      <td>1001</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1050</td>\n",
       "      <td>0.328796</td>\n",
       "      <td>0.718626</td>\n",
       "      <td>0.718626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BUO</td>\n",
       "      <td>De Burd</td>\n",
       "      <td>FryslÃ¢n</td>\n",
       "      <td>1012</td>\n",
       "      <td>189.500000</td>\n",
       "      <td>1170</td>\n",
       "      <td>0.328796</td>\n",
       "      <td>0.718626</td>\n",
       "      <td>0.718626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BUW</td>\n",
       "      <td>De Burd</td>\n",
       "      <td>FryslÃ¢n</td>\n",
       "      <td>4002</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>15130</td>\n",
       "      <td>0.321479</td>\n",
       "      <td>0.591286</td>\n",
       "      <td>0.591286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CAM</td>\n",
       "      <td>Capmhyus</td>\n",
       "      <td>Drenthe</td>\n",
       "      <td>1001</td>\n",
       "      <td>160.666667</td>\n",
       "      <td>1050</td>\n",
       "      <td>0.328796</td>\n",
       "      <td>0.718626</td>\n",
       "      <td>0.718626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DEM</td>\n",
       "      <td>Demmerik</td>\n",
       "      <td>Utrecht</td>\n",
       "      <td>1001</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1050</td>\n",
       "      <td>0.328796</td>\n",
       "      <td>0.718626</td>\n",
       "      <td>0.718626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HOC</td>\n",
       "      <td>Hommerts</td>\n",
       "      <td>FryslÃ¢n</td>\n",
       "      <td>1015</td>\n",
       "      <td>174.500000</td>\n",
       "      <td>1200</td>\n",
       "      <td>0.328796</td>\n",
       "      <td>0.718626</td>\n",
       "      <td>0.718626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HOH</td>\n",
       "      <td>Hommerts</td>\n",
       "      <td>FryslÃ¢n</td>\n",
       "      <td>1015</td>\n",
       "      <td>159.750000</td>\n",
       "      <td>1200</td>\n",
       "      <td>0.328796</td>\n",
       "      <td>0.718626</td>\n",
       "      <td>0.718626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ILP_PT</td>\n",
       "      <td>Iiperveld</td>\n",
       "      <td>Noord-Holland</td>\n",
       "      <td>1006</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1281</td>\n",
       "      <td>0.319729</td>\n",
       "      <td>0.765452</td>\n",
       "      <td>0.765452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LAW_MOB</td>\n",
       "      <td>Langeweide</td>\n",
       "      <td>Zuid-Holland</td>\n",
       "      <td>1018</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1130</td>\n",
       "      <td>0.328796</td>\n",
       "      <td>0.718626</td>\n",
       "      <td>0.718626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LAW_MS</td>\n",
       "      <td>Langeweide</td>\n",
       "      <td>Zuid-Holland</td>\n",
       "      <td>1018</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1130</td>\n",
       "      <td>0.328796</td>\n",
       "      <td>0.718626</td>\n",
       "      <td>0.718626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LDC</td>\n",
       "      <td>Lyste Deelen</td>\n",
       "      <td>FryslÃ¢n</td>\n",
       "      <td>1006</td>\n",
       "      <td>128.500000</td>\n",
       "      <td>1281</td>\n",
       "      <td>0.319729</td>\n",
       "      <td>0.765452</td>\n",
       "      <td>0.765452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LDH</td>\n",
       "      <td>Lyste Deelen</td>\n",
       "      <td>FryslÃ¢n</td>\n",
       "      <td>1006</td>\n",
       "      <td>160.750000</td>\n",
       "      <td>1281</td>\n",
       "      <td>0.319729</td>\n",
       "      <td>0.765452</td>\n",
       "      <td>0.765452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ONL</td>\n",
       "      <td>Onlanden</td>\n",
       "      <td>Drenthe</td>\n",
       "      <td>1001</td>\n",
       "      <td>136.750000</td>\n",
       "      <td>1050</td>\n",
       "      <td>0.328796</td>\n",
       "      <td>0.718626</td>\n",
       "      <td>0.718626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>WRW_SR</td>\n",
       "      <td>Weerribben</td>\n",
       "      <td>Overijssel</td>\n",
       "      <td>1006</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1281</td>\n",
       "      <td>0.319729</td>\n",
       "      <td>0.765452</td>\n",
       "      <td>0.765452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ZEG_MOB</td>\n",
       "      <td>Zegveld</td>\n",
       "      <td>Utrecht</td>\n",
       "      <td>1018</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1130</td>\n",
       "      <td>0.328796</td>\n",
       "      <td>0.718626</td>\n",
       "      <td>0.718626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ZEG_PT</td>\n",
       "      <td>Zegveld</td>\n",
       "      <td>Utrecht</td>\n",
       "      <td>1018</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1130</td>\n",
       "      <td>0.328796</td>\n",
       "      <td>0.718626</td>\n",
       "      <td>0.718626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Site_ID       Site_Name       Province  BOFEK_2020_Physical Units  \\\n",
       "0    ALB_MS  Aldeboam North        FryslÃ¢n                       1018   \n",
       "1    ALB_RF  Aldeboam North        FryslÃ¢n                       1018   \n",
       "2       AMM  Aldeboam Maize        FryslÃ¢n                       1006   \n",
       "3       AMR  Aldeboam Maize        FryslÃ¢n                       1006   \n",
       "4    ANK_PT        Ankeveen  Noord-Holland                       1006   \n",
       "5    ASD_MP      Assendelft  Noord-Holland                       1001   \n",
       "6       BUO         De Burd        FryslÃ¢n                       1012   \n",
       "7       BUW         De Burd        FryslÃ¢n                       4002   \n",
       "8       CAM        Capmhyus        Drenthe                       1001   \n",
       "9       DEM        Demmerik        Utrecht                       1001   \n",
       "10      HOC        Hommerts        FryslÃ¢n                       1015   \n",
       "11      HOH        Hommerts        FryslÃ¢n                       1015   \n",
       "12   ILP_PT       Iiperveld  Noord-Holland                       1006   \n",
       "13  LAW_MOB      Langeweide   Zuid-Holland                       1018   \n",
       "14   LAW_MS      Langeweide   Zuid-Holland                       1018   \n",
       "15      LDC    Lyste Deelen        FryslÃ¢n                       1006   \n",
       "16      LDH    Lyste Deelen        FryslÃ¢n                       1006   \n",
       "17      ONL        Onlanden        Drenthe                       1001   \n",
       "18   WRW_SR      Weerribben     Overijssel                       1006   \n",
       "19  ZEG_MOB         Zegveld        Utrecht                       1018   \n",
       "20   ZEG_PT         Zegveld        Utrecht                       1018   \n",
       "\n",
       "    Peat_Thickness_2022  Dominant_iProfile        WP       SAT  Porosity  \n",
       "0            143.750000               1130  0.328796  0.718626  0.718626  \n",
       "1            143.250000               1130  0.328796  0.718626  0.718626  \n",
       "2            193.500000               1281  0.319729  0.765452  0.765452  \n",
       "3            184.500000               1281  0.319729  0.765452  0.765452  \n",
       "4             -1.000000               1281  0.319729  0.765452  0.765452  \n",
       "5             -1.000000               1050  0.328796  0.718626  0.718626  \n",
       "6            189.500000               1170  0.328796  0.718626  0.718626  \n",
       "7             -1.000000              15130  0.321479  0.591286  0.591286  \n",
       "8            160.666667               1050  0.328796  0.718626  0.718626  \n",
       "9             -1.000000               1050  0.328796  0.718626  0.718626  \n",
       "10           174.500000               1200  0.328796  0.718626  0.718626  \n",
       "11           159.750000               1200  0.328796  0.718626  0.718626  \n",
       "12            -1.000000               1281  0.319729  0.765452  0.765452  \n",
       "13            -1.000000               1130  0.328796  0.718626  0.718626  \n",
       "14            -1.000000               1130  0.328796  0.718626  0.718626  \n",
       "15           128.500000               1281  0.319729  0.765452  0.765452  \n",
       "16           160.750000               1281  0.319729  0.765452  0.765452  \n",
       "17           136.750000               1050  0.328796  0.718626  0.718626  \n",
       "18            -1.000000               1281  0.319729  0.765452  0.765452  \n",
       "19            -1.000000               1130  0.328796  0.718626  0.718626  \n",
       "20            -1.000000               1130  0.328796  0.718626  0.718626  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Merge results back, ensure we don't duplicate columns if run multiple times\n",
    "if 'WP' in sites_df.columns: sites_df.drop(columns=['WP'], inplace=True)\n",
    "if 'SAT' in sites_df.columns: sites_df.drop(columns=['SAT'], inplace=True)\n",
    "if 'Porosity' in sites_df.columns: sites_df.drop(columns=['Porosity'], inplace=True)\n",
    "\n",
    "# Use the original sites_df and merge results based on Site_ID\n",
    "sites_df_final = pd.merge(sites_df, results_df, on=site_id_col, how='left')\n",
    "\n",
    "#sites_df_final.info()\n",
    "sites_df_final.head(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "779d2a2e-32d4-46be-b3dc-164b80c19cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame successfully saved to C:/Data_MSc_Thesis/BOFEK/WP_SAT_BOFEK.csv\n"
     ]
    }
   ],
   "source": [
    "output_path = \"C:/Data_MSc_Thesis/BOFEK/WP_SAT_BOFEK.csv\"\n",
    "sites_df_final.to_csv(output_path, index=False)\n",
    "print(f\"DataFrame successfully saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
