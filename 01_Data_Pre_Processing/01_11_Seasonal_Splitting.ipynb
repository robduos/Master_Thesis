{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "06e8da51-2519-42e5-95d9-da8a32688eba",
   "metadata": {},
   "source": [
    "**Script Description:** This script loads the complete merged dataset, and splits the dataset to two seasonal periods.\n",
    "\n",
    "**File Name:** 01_11_Seasonal_Splitting.ipynb\n",
    "\n",
    "**Date:** 2025\n",
    "\n",
    "**Created by:** Rob Alamgir  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5bf83d-42a1-4cc4-a531-393c270da57d",
   "metadata": {},
   "source": [
    "#### Import the relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53c2becc-cd40-48c6-b57c-646da7c84abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4485e2-7d13-430d-81b3-94b91f6a863b",
   "metadata": {},
   "source": [
    "#### Step 1: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9318d96-9800-4bff-a7d5-7220bfb31568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 36056 entries, 0 to 36055\n",
      "Columns: 109 entries, Date to week_number\n",
      "dtypes: datetime64[ns](1), float64(104), int64(2), object(2)\n",
      "memory usage: 30.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "data_path = \"C:/Data_MSc_Thesis/Pre_Processed_Data_Final/Pre_Processed_Data_All_Locations_V6.csv\"\n",
    "complete_dataset = pd.read_csv(data_path, low_memory=False)\n",
    "complete_dataset['Date'] = pd.to_datetime(complete_dataset['Date']) # Convert 'date' column to datetime format\n",
    "print(complete_dataset.info()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c363f03-ebee-4195-9311-d663a7afac6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'Date' column is in datetime format\n",
    "complete_dataset['Date'] = pd.to_datetime(complete_dataset['Date'])\n",
    "\n",
    "# Define seasons\n",
    "complete_dataset['Season'] = complete_dataset['Date'].dt.month.map(\n",
    "    lambda x: 'Wet' if x in [10, 11, 12, 1, 2, 3] else 'Dry')\n",
    "\n",
    "# Compute hydrological balance (Rainfall - ET)\n",
    "complete_dataset['Hydro_Balance'] = complete_dataset['RAIN_f'] - complete_dataset['ET']\n",
    "\n",
    "# Classify into deficit (negative) or surplus (positive)\n",
    "complete_dataset['Hydro_Status'] = complete_dataset['Hydro_Balance'].apply(\n",
    "    lambda x: 'Deficit' if x < 0 else 'Surplus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2c16f1f-f9db-40b8-84aa-ffd6d0fe2e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 36056 entries, 0 to 36055\n",
      "Columns: 112 entries, Date to Hydro_Status\n",
      "dtypes: datetime64[ns](1), float64(105), int64(2), object(4)\n",
      "memory usage: 30.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Check updated dataframe\n",
    "#complete_dataset.head(10)\n",
    "print(complete_dataset.info()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c51ffd13-651a-44fe-9d99-e635573a66ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hydro_Wet_Season: 17559 rows\n",
      "Hydro_Dry_Season: 18497 rows\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset based on the 'Season' column\n",
    "Hydro_Wet_Season = complete_dataset[complete_dataset['Season'] == 'Wet'].copy()\n",
    "Hydro_Dry_Season = complete_dataset[complete_dataset['Season'] == 'Dry'].copy()\n",
    "\n",
    "# Display the number of rows in each dataframe\n",
    "print(f\"Hydro_Wet_Season: {Hydro_Wet_Season.shape[0]} rows\")\n",
    "print(f\"Hydro_Dry_Season: {Hydro_Dry_Season.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a3087c-32f5-49f1-a8b2-9871f6ba2fca",
   "metadata": {},
   "source": [
    "#### Export the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b04c77c-ea94-4a98-a229-d35b3b85bb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hydro_Wet_Season dataset exported to C:/Data_MSc_Thesis/Pre_Processed_Data_Final/Pre_Processed_Data_All_Locations_Updated_V6_Wet.csv.\n",
      "Hydro_Dry_Season dataset exported to C:/Data_MSc_Thesis/Pre_Processed_Data_Final/Pre_Processed_Data_All_Locations_Updated_V6_Dry.csv.\n"
     ]
    }
   ],
   "source": [
    "# Define file paths for export\n",
    "Hydro_Wet_Season_data_path = \"C:/Data_MSc_Thesis/Pre_Processed_Data_Final/Pre_Processed_Data_All_Locations_Updated_V6_Wet.csv\"\n",
    "Hydro_Dry_Season_data_path = \"C:/Data_MSc_Thesis/Pre_Processed_Data_Final/Pre_Processed_Data_All_Locations_Updated_V6_Dry.csv\"\n",
    "\n",
    "# Export summer and winter data to CSV\n",
    "Hydro_Wet_Season.to_csv(Hydro_Wet_Season_data_path, index=False)\n",
    "Hydro_Dry_Season.to_csv(Hydro_Dry_Season_data_path, index=False)\n",
    "\n",
    "print(f\"Hydro_Wet_Season dataset exported to {Hydro_Wet_Season_data_path}.\")\n",
    "print(f\"Hydro_Dry_Season dataset exported to {Hydro_Dry_Season_data_path}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
